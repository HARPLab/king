Timer unit: 1e-06 s

Total time: 184.379 s
File: generate_scenarios.py
Function: unroll_simulation at line 427

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   427                                               @profile
   428                                               def unroll_simulation(self):
   429                                                   """
   430                                                   Simulates one episode of length `args.sim_horizon` in the differentiable
   431                                                   simulator.
   432                                                   """
   433                                                   # initializations
   434       103        137.3      1.3      0.0          semantic_grid = self.simulator.map
   435       103        160.0      1.6      0.0          cost_dict = {"ego_col": [], "adv_rd": [], "adv_col": []}
   436                                           
   437       103         31.4      0.3      0.0          num_oob_agents_per_t = []
   438       103        126.6      1.2      0.0          if self.args.renderer_class == 'CARLA':
   439                                                       self.simulator.renderer.initialize_carla_state(
   440                                                           self.simulator.get_ego_state(),
   441                                                           self.simulator.get_adv_state(),
   442                                                           town=self.town,
   443                                                       )
   444                                           
   445                                                       rgb_per_t = []
   446                                                       observations_per_t = []
   447                                                       lidar_per_t1 = []
   448                                                       lidar_per_t2 = []
   449                                           
   450       103         25.9      0.3      0.0          segbevL = []
   451      8316       4399.9      0.5      0.0          for t in range(self.args.sim_horizon):
   452      8214    2184723.0    266.0      1.2              input_data = self.simulator.get_ego_sensor()
   453      8214      16344.7      2.0      0.0              if(self.args.ego_agent == 'PlanT'):
   454                                                           input_data.update({"hd_map": {"vehWorld": self.simulator.renderer.hero_actor, "opendrive": self.simulator.carla_wrapper.map.to_opendrive()}})
   455                                                       #     actorList = self.simulator.carla_wrapper.world.get_actors()
   456                                                       #     for actor in actorList:
   457                                                       #         if(actor.attributes["role_name"] == "hero"):
   458                                                       #             print("Ego Vehicle Found!")
   459                                                       #             break
   460      8214       8674.2      1.1      0.0              input_data.update({"timestep": self.simulator.timestep})
   461                                           
   462      8214   11700463.7   1424.5      6.3              observations, _ = self.simulator.renderer.get_observations(semantic_grid, self.simulator.get_ego_state(), self.simulator.get_adv_state())
   463      8214      11529.7      1.4      0.0              input_data.update(observations)
   464                                                       #segbevL.append(input_data['birdview'])
   465                                           
   466      8214  107220173.8  13053.3     58.2              ego_actions = self.simulator.ego_policy.run_step(input_data, self.simulator)
   467                                           
   468      8213       9132.8      1.1      0.0              if self.args.detach_ego_path:
   469      8213      89133.5     10.9      0.0                  ego_actions["steer"] = ego_actions["steer"].detach()
   470      8213      64684.5      7.9      0.0                  ego_actions["throttle"] = ego_actions["throttle"].detach()
   471      8213      30768.0      3.7      0.0                  ego_actions["brake"] = ego_actions["brake"].detach()
   472                                           
   473      8213     646005.4     78.7      0.4              adv_actions = self.simulator.adv_policy.run_step(input_data)
   474                                           
   475      8213   13049714.7   1588.9      7.1              num_oob_agents = self.simulator.run_termination_checks()
   476      8213       6610.8      0.8      0.0              num_oob_agents_per_t.append(num_oob_agents)
   477                                           
   478      8213   38715725.0   4714.0     21.0              ego_col_cost, adv_col_cost, adv_rd_cost = self.compute_cost()
   479                                           
   480      8213      10451.4      1.3      0.0              cost_dict["adv_rd"].append(adv_rd_cost)
   481      8213       4583.5      0.6      0.0              cost_dict["adv_col"].append(adv_col_cost)
   482      8213       4927.1      0.6      0.0              cost_dict["ego_col"].append(ego_col_cost)
   483                                           
   484                                                       # compute next state given current state and actions
   485      8213   10567598.8   1286.7      5.7              self.simulator.step(ego_actions, adv_actions)
   486                                           
   487                                                   # stack timesteps for oob metric
   488       102      21419.8    210.0      0.0          num_oob_agents_per_t = torch.stack(num_oob_agents_per_t, dim=1)
   489                                                   #torch.save(segbevL, 'segbev.pt')
   490                                           
   491       102      10943.0    107.3      0.0          torch.cuda.empty_cache()
   492       102         32.0      0.3      0.0          return cost_dict, num_oob_agents_per_t

184.38 seconds - generate_scenarios.py:427 - unroll_simulation
